{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "song_generation_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4aHK2CYygXom"
      },
      "source": [
        "## Import TensorFlow and related functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2LmLTREBf5ng",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Other imports for processing data\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4Bf5FVHfganK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "1c1e2516-521c-4a25-e374-97b9bb64ec94"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n",
        "    -O /tmp/songdata.csv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-27 16:55:46--  https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving drive.google.com (drive.google.com)... 173.194.76.101, 173.194.76.139, 173.194.76.138, ...\n",
            "Connecting to drive.google.com (drive.google.com)|173.194.76.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/pb8dmrm2utecqfjror2r0q7qpvqtkn3h/1593276900000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-06-27 16:55:49--  https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/pb8dmrm2utecqfjror2r0q7qpvqtkn3h/1593276900000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)... 173.194.76.132, 2a00:1450:400c:c00::84\n",
            "Connecting to doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)|173.194.76.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/csv]\n",
            "Saving to: ‘/tmp/songdata.csv’\n",
            "\n",
            "/tmp/songdata.csv       [    <=>             ]  69.08M  89.0MB/s    in 0.8s    \n",
            "\n",
            "2020-06-27 16:55:50 (89.0 MB/s) - ‘/tmp/songdata.csv’ saved [72436445]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nWbMN_19jfRT"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LRmPPJegovBe",
        "colab": {}
      },
      "source": [
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "def create_lyrics_corpus(dataset, field):\n",
        "  # Remove all other punctuation\n",
        "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
        "  # Make it lowercase\n",
        "  dataset[field] = dataset[field].str.lower()\n",
        "  # Make it one long string to split by line\n",
        "  lyrics = dataset[field].str.cat()\n",
        "  corpus = lyrics.split('\\n')\n",
        "  # Remove any trailing whitespace\n",
        "  for l in range(len(corpus)):\n",
        "    corpus[l] = corpus[l].rstrip()\n",
        "  # Remove any empty lines\n",
        "  corpus = [l for l in corpus if l != '']\n",
        "\n",
        "  return corpus"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kIGedF3XjHj4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4d760e66-7cad-4785-a609-4f7f99c00b0b"
      },
      "source": [
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "# Read the dataset from csv - this time with 250 songs\n",
        "dataset = pd.read_csv('/tmp/songdata.csv', dtype=str)[:250]\n",
        "# Create the corpus using the 'text' column containing lyrics\n",
        "corpus = create_lyrics_corpus(dataset, 'text')\n",
        "# Tokenize the corpus\n",
        "tokenizer = tokenize_corpus(corpus, num_words=2000)\n",
        "total_words = tokenizer.num_words\n",
        "\n",
        "# There should be a lot more words now\n",
        "print(total_words)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "quoDmw_FkNBA"
      },
      "source": [
        "### Create Sequences and Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kkLAf3HmkPSo",
        "colab": {}
      },
      "source": [
        "sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tsequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences for equal input length \n",
        "max_sequence_len = max([len(seq) for seq in sequences])\n",
        "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
        "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
        "# One-hot encode the labels\n",
        "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cECbqT-blMk-"
      },
      "source": [
        "### Train a Text Generation Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7nHOp6uWlP_P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c2e5e18-e6d9-449b-f4af-4f314b32edbe"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(20)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(input_sequences, one_hot_labels, epochs=100, verbose=1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 5.9772 - accuracy: 0.0470\n",
            "Epoch 2/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 5.6377 - accuracy: 0.0559\n",
            "Epoch 3/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 5.4097 - accuracy: 0.0841\n",
            "Epoch 4/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 5.2443 - accuracy: 0.1005\n",
            "Epoch 5/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 5.1076 - accuracy: 0.1164\n",
            "Epoch 6/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 4.9486 - accuracy: 0.1329\n",
            "Epoch 7/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 4.7809 - accuracy: 0.1493\n",
            "Epoch 8/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 4.6322 - accuracy: 0.1640\n",
            "Epoch 9/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 4.5070 - accuracy: 0.1768\n",
            "Epoch 10/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 4.3898 - accuracy: 0.1886\n",
            "Epoch 11/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 4.2837 - accuracy: 0.2014\n",
            "Epoch 12/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 4.1874 - accuracy: 0.2122\n",
            "Epoch 13/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 4.0998 - accuracy: 0.2226\n",
            "Epoch 14/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 4.0212 - accuracy: 0.2324\n",
            "Epoch 15/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 3.9472 - accuracy: 0.2426\n",
            "Epoch 16/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 3.8791 - accuracy: 0.2518\n",
            "Epoch 17/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 3.8125 - accuracy: 0.2598\n",
            "Epoch 18/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 3.7520 - accuracy: 0.2686\n",
            "Epoch 19/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 3.6967 - accuracy: 0.2767\n",
            "Epoch 20/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 3.6469 - accuracy: 0.2839\n",
            "Epoch 21/100\n",
            "1480/1480 [==============================] - 21s 15ms/step - loss: 3.5932 - accuracy: 0.2926\n",
            "Epoch 22/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 3.5489 - accuracy: 0.2980\n",
            "Epoch 23/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 3.5103 - accuracy: 0.3046\n",
            "Epoch 24/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 3.4689 - accuracy: 0.3095\n",
            "Epoch 25/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 3.4299 - accuracy: 0.3164\n",
            "Epoch 26/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 3.3900 - accuracy: 0.3218\n",
            "Epoch 27/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 3.3591 - accuracy: 0.3255\n",
            "Epoch 28/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 3.3258 - accuracy: 0.3323\n",
            "Epoch 29/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 3.2956 - accuracy: 0.3349\n",
            "Epoch 30/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 3.2594 - accuracy: 0.3419\n",
            "Epoch 31/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 3.2342 - accuracy: 0.3456\n",
            "Epoch 32/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 3.2045 - accuracy: 0.3506\n",
            "Epoch 33/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 3.1718 - accuracy: 0.3559\n",
            "Epoch 34/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 3.1455 - accuracy: 0.3602\n",
            "Epoch 35/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 3.1194 - accuracy: 0.3643\n",
            "Epoch 36/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 3.1003 - accuracy: 0.3668\n",
            "Epoch 37/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 3.0677 - accuracy: 0.3725\n",
            "Epoch 38/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 3.0436 - accuracy: 0.3750\n",
            "Epoch 39/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 3.0215 - accuracy: 0.3820\n",
            "Epoch 40/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 3.0007 - accuracy: 0.3836\n",
            "Epoch 41/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.9782 - accuracy: 0.3865\n",
            "Epoch 42/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.9586 - accuracy: 0.3936\n",
            "Epoch 43/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.9381 - accuracy: 0.3975\n",
            "Epoch 44/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.9169 - accuracy: 0.4009\n",
            "Epoch 45/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.8983 - accuracy: 0.4039\n",
            "Epoch 46/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.8831 - accuracy: 0.4053\n",
            "Epoch 47/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.8666 - accuracy: 0.4097\n",
            "Epoch 48/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.8572 - accuracy: 0.4085\n",
            "Epoch 49/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.8486 - accuracy: 0.4110\n",
            "Epoch 50/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.8101 - accuracy: 0.4182\n",
            "Epoch 51/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.7930 - accuracy: 0.4206\n",
            "Epoch 52/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.7834 - accuracy: 0.4224\n",
            "Epoch 53/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.7700 - accuracy: 0.4244\n",
            "Epoch 54/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.7472 - accuracy: 0.4262\n",
            "Epoch 55/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.7404 - accuracy: 0.4286\n",
            "Epoch 56/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.7172 - accuracy: 0.4331\n",
            "Epoch 57/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.7070 - accuracy: 0.4337\n",
            "Epoch 58/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.6902 - accuracy: 0.4370\n",
            "Epoch 59/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.6819 - accuracy: 0.4382\n",
            "Epoch 60/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.6776 - accuracy: 0.4392\n",
            "Epoch 61/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.6559 - accuracy: 0.4433\n",
            "Epoch 62/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.6652 - accuracy: 0.4408\n",
            "Epoch 63/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.6285 - accuracy: 0.4485\n",
            "Epoch 64/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.6140 - accuracy: 0.4507\n",
            "Epoch 65/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.6017 - accuracy: 0.4530\n",
            "Epoch 66/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.5931 - accuracy: 0.4540\n",
            "Epoch 67/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.5847 - accuracy: 0.4543\n",
            "Epoch 68/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.5718 - accuracy: 0.4561\n",
            "Epoch 69/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.5675 - accuracy: 0.4581\n",
            "Epoch 70/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.5456 - accuracy: 0.4619\n",
            "Epoch 71/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.5482 - accuracy: 0.4608\n",
            "Epoch 72/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.5324 - accuracy: 0.4649\n",
            "Epoch 73/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.5267 - accuracy: 0.4648\n",
            "Epoch 74/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.5105 - accuracy: 0.4663\n",
            "Epoch 75/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.5204 - accuracy: 0.4655\n",
            "Epoch 76/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.4912 - accuracy: 0.4703\n",
            "Epoch 77/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.4773 - accuracy: 0.4729\n",
            "Epoch 78/100\n",
            "1480/1480 [==============================] - 20s 14ms/step - loss: 2.4733 - accuracy: 0.4733\n",
            "Epoch 79/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.4653 - accuracy: 0.4757\n",
            "Epoch 80/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.4550 - accuracy: 0.4780\n",
            "Epoch 81/100\n",
            "1480/1480 [==============================] - 22s 15ms/step - loss: 2.4564 - accuracy: 0.4779\n",
            "Epoch 82/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.4521 - accuracy: 0.4793\n",
            "Epoch 83/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.4282 - accuracy: 0.4828\n",
            "Epoch 84/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.4190 - accuracy: 0.4839\n",
            "Epoch 85/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.4198 - accuracy: 0.4826\n",
            "Epoch 86/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.4052 - accuracy: 0.4846\n",
            "Epoch 87/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.4011 - accuracy: 0.4864\n",
            "Epoch 88/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.3836 - accuracy: 0.4913\n",
            "Epoch 89/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.3826 - accuracy: 0.4916\n",
            "Epoch 90/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.3716 - accuracy: 0.4941\n",
            "Epoch 91/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.3671 - accuracy: 0.4939\n",
            "Epoch 92/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.3485 - accuracy: 0.4973\n",
            "Epoch 93/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.3498 - accuracy: 0.4962\n",
            "Epoch 94/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.3465 - accuracy: 0.4976\n",
            "Epoch 95/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.3392 - accuracy: 0.4974\n",
            "Epoch 96/100\n",
            "1480/1480 [==============================] - 22s 15ms/step - loss: 2.3223 - accuracy: 0.5013\n",
            "Epoch 97/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.3412 - accuracy: 0.4975\n",
            "Epoch 98/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.3185 - accuracy: 0.5018\n",
            "Epoch 99/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.3029 - accuracy: 0.5061\n",
            "Epoch 100/100\n",
            "1480/1480 [==============================] - 21s 14ms/step - loss: 2.3008 - accuracy: 0.5057\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MgvIz20nlQcq"
      },
      "source": [
        "### View the Training Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rOqmmarvlSLh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "470bb4df-34ef-4bbf-fedf-4706da1fdd38"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ISLZZGlQlSxh"
      },
      "source": [
        "### Generate lyrics!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P96oVMk3lU7y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "5ebc0a20-2922-479c-81b9-f55d62677cf1"
      },
      "source": [
        "seed_text = \"i love chocolates\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i love chocolates it all have a few things can go old story time can do is right my love on her way down down out the hole in guys happiest side mans bill sea silly remind excite spread twist spread spread spread spread spread twist spread spread spread spread spread twist borrow spread excite fans deny twist deny refuse dig refuse tip deny deny kill dig resist resist happiest defenses dig happiest wall beating folks catch me for evergrowing singing rockin singing returning the bars pandora hour fellow were shining know what she could be sailing for returning whatever well then suddenly\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "upgJKV8_oRU9"
      },
      "source": [
        "### Varying the Possible Outputs\n",
        "\n",
        "In running the above, you may notice that the same seed text will generate similar outputs. This is because the code is currently always choosing the top predicted class as the next word. What if you wanted more variance in the output? \n",
        "\n",
        "Switching from `model.predict_classes` to `model.predict_proba` will get us all of the class probabilities. We can combine this with `np.random.choice` to select a given predicted output based on a probability, thereby giving a bit more randomness to our outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lZe9gaJeoGVP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3c3735af-f9f0-40e6-fe69-60d1136cd000"
      },
      "source": [
        "# Test the method with just the first word after the seed text\n",
        "seed_text = \"i love chocolates\"\n",
        "next_words = 100\n",
        "  \n",
        "token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "predicted_probs = model.predict(token_list)[0]\n",
        "predicted = np.random.choice([x for x in range(len(predicted_probs))], \n",
        "                             p=predicted_probs)\n",
        "# Running this cell multiple times should get you some variance in output\n",
        "print(predicted)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ee7WKgRGrJy1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "9562e248-8b78-4440-afe9-f638acbf62ec"
      },
      "source": [
        "# Use this process for the full output generation\n",
        "seed_text = \"i love chocolates\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "  predicted_probs = model.predict(token_list)[0]\n",
        "  predicted = np.random.choice([x for x in range(len(predicted_probs))],\n",
        "                               p=predicted_probs)\n",
        "  output_word = \"\"\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted:\n",
        "      output_word = word\n",
        "      break\n",
        "  seed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i love chocolates for my face about a maybe on give your choice but it heard me i would have a past then you promise that rides gets me rides on the sun that wed want to see em unreal at the time that you would sees you heaven can go forever praised women last from there twist with times then he praised hoping sun done cause shed make plans i could be well cause god heads and tails you everything everywhere we so hard ya through loud for noone thats never done that let you wasnt check kids kin walk my intention\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}